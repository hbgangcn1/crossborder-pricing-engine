"""
è‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿ
æä¾›å®šæœŸè‡ªåŠ¨å¤‡ä»½ã€å¤‡ä»½éªŒè¯ã€è‡ªåŠ¨æ¸…ç†ç­‰åŠŸèƒ½
"""

import os
import sqlite3
import shutil
import time
import threading
from datetime import datetime
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—


def _setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®ï¼Œé¿å…æ¨¡å—çº§é…ç½®å¯¼è‡´çš„é—®é¢˜"""
    # æ£€æŸ¥æ˜¯å¦å·²ç»é…ç½®è¿‡æ—¥å¿—
    if not logging.getLogger().handlers:
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('backup.log', encoding='utf-8'),
                logging.StreamHandler(),
            ],
        )


# å»¶è¿Ÿåˆå§‹åŒ–æ—¥å¿—
_setup_logging()


def _load_schedule_module():
    """æƒ°æ€§åŠ è½½ schedule æ¨¡å—ï¼Œç¼ºå¤±æ—¶è¿”å› Noneã€‚

    è¿™æ ·é¿å…æ¨¡å—çº§å¸¸é‡å¯¼è‡´çš„â€œä¸å¯åˆ°è¾¾ä»£ç â€é™æ€åˆ†æå‘Šè­¦ã€‚
    """
    try:  # pragma: no cover - ä»…åœ¨è¿è¡Œç¯å¢ƒå­˜åœ¨æ—¶åŠ è½½
        import schedule as _schedule  # type: ignore
        return _schedule
    except ImportError:
        return None


class AutoBackupSystem:
    def __init__(self, db_path="pricing_system.db", backup_dir="backups"):
        self.db_path = db_path
        self.backup_dir = backup_dir
        self.backup_interval_hours = 6  # æ¯6å°æ—¶å¤‡ä»½ä¸€æ¬¡
        self.max_backups = 10  # ä¿ç•™æœ€è¿‘10ä¸ªå¤‡ä»½
        self.backup_thread = None
        self.is_running = False

        # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
        Path(backup_dir).mkdir(exist_ok=True)

    def create_backup(self):
        """åˆ›å»ºæ•°æ®åº“å¤‡ä»½"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"auto_backup_{timestamp}.db"
            backup_path = os.path.join(self.backup_dir, backup_filename)

            # å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
            shutil.copy2(self.db_path, backup_path)
            # éªŒè¯å¤‡ä»½
            if self.verify_backup(backup_path):
                logging.info(f"âœ… è‡ªåŠ¨å¤‡ä»½æˆåŠŸ: {backup_filename}")
                self.cleanup_old_backups()
                return True
            else:
                logging.error(f"âŒ å¤‡ä»½éªŒè¯å¤±è´¥: {backup_filename}")
                os.remove(backup_path)
                return False

        except (OSError, sqlite3.Error) as e:
            logging.error(f"âŒ å¤‡ä»½å¤±è´¥: {str(e)}")
            return False

    @staticmethod
    def verify_backup(backup_path):
        """éªŒè¯å¤‡ä»½æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        try:
            conn = sqlite3.connect(backup_path)
            c = conn.cursor()

            # æ£€æŸ¥å…³é”®è¡¨æ˜¯å¦å­˜åœ¨
            tables = ['users', 'products', 'logistics']
            for table in tables:
                c.execute(f"SELECT COUNT(*) FROM {table}")
                count = c.fetchone()[0]
                logging.info(f"å¤‡ä»½éªŒè¯ - {table}: {count} æ¡è®°å½•")

            conn.close()
            return True

        except (sqlite3.Error, OSError) as e:
            logging.error(f"å¤‡ä»½éªŒè¯å¤±è´¥: {str(e)}")
            return False

    def cleanup_old_backups(self):
        """æ¸…ç†æ—§çš„å¤‡ä»½æ–‡ä»¶"""
        try:
            backup_files = []
            for fname in os.listdir(self.backup_dir):
                if (
                    fname.startswith("auto_backup_")
                    and fname.endswith(".db")
                ):
                    file_path = os.path.join(self.backup_dir, fname)
                    backup_files.append(
                        (file_path, os.path.getmtime(file_path))
                    )

            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„
            backup_files.sort(key=lambda x: x[1], reverse=True)

            # åˆ é™¤å¤šä½™çš„å¤‡ä»½
            if len(backup_files) > self.max_backups:
                for file_path, _ in backup_files[self.max_backups:]:
                    os.remove(file_path)
                    logging.info(
                        "ğŸ—‘ï¸ åˆ é™¤æ—§å¤‡ä»½: %s",
                        os.path.basename(file_path),
                    )

        except (OSError, FileNotFoundError) as e:
            logging.error(f"æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: {str(e)}")

    def get_backup_stats(self):
        """è·å–å¤‡ä»½ç»Ÿè®¡ä¿¡æ¯"""
        try:
            backup_files = []
            total_size = 0

            for fname in os.listdir(self.backup_dir):
                if (
                    fname.startswith("auto_backup_")
                    and fname.endswith(".db")
                ):
                    file_path = os.path.join(self.backup_dir, fname)
                    size = os.path.getsize(file_path)
                    mtime = os.path.getmtime(file_path)
                    backup_files.append(
                        {
                            'name': fname,
                            'size': size,
                            'mtime': datetime.fromtimestamp(mtime),
                        }
                    )
                    total_size += size

            return {
                'count': len(backup_files),
                'total_size_mb': round(total_size / (1024 * 1024), 2),
                'files': sorted(
                    backup_files,
                    key=lambda x: x['mtime'],
                    reverse=True,
                ),
            }

        except (OSError, FileNotFoundError) as e:
            logging.error(f"è·å–å¤‡ä»½ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return None

    def restore_from_backup(self, backup_filename):
        """ä»å¤‡ä»½æ–‡ä»¶æ¢å¤æ•°æ®åº“"""
        try:
            backup_path = os.path.join(self.backup_dir, backup_filename)

            if not os.path.exists(backup_path):
                logging.error(f"å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_filename}")
                return False

            # éªŒè¯å¤‡ä»½æ–‡ä»¶
            if not self.verify_backup(backup_path):
                logging.error(f"å¤‡ä»½æ–‡ä»¶éªŒè¯å¤±è´¥: {backup_filename}")
                return False

            # åˆ›å»ºå½“å‰æ•°æ®åº“çš„å¤‡ä»½
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            current_backup = f"pre_restore_backup_{timestamp}.db"
            shutil.copy2(
                self.db_path,
                os.path.join(self.backup_dir, current_backup),
            )
            # æ¢å¤æ•°æ®åº“
            shutil.copy2(backup_path, self.db_path)

            logging.info(f"âœ… æ•°æ®åº“æ¢å¤æˆåŠŸ: {backup_filename}")
            return True

        except (OSError, FileNotFoundError, sqlite3.Error) as e:
            logging.error(f"âŒ æ•°æ®åº“æ¢å¤å¤±è´¥: {str(e)}")
            return False

    def start_auto_backup(self):
        """å¯åŠ¨è‡ªåŠ¨å¤‡ä»½"""
        if self.is_running:
            logging.warning("è‡ªåŠ¨å¤‡ä»½å·²åœ¨è¿è¡Œä¸­")
            return

        self.is_running = True

        # ç«‹å³åˆ›å»ºä¸€æ¬¡å¤‡ä»½
        self.create_backup()

        sched = _load_schedule_module()

        def run_scheduler_with_schedule():
            # ä½¿ç”¨ç¬¬ä¸‰æ–¹ schedule åº“
            while self.is_running:
                try:
                    sched.run_pending()  # type: ignore[union-attr]
                except Exception as sched_exc:
                    logging.exception("è°ƒåº¦è¿è¡Œé”™è¯¯: %s", sched_exc)
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

        def run_scheduler_fallback():
            # æ—  schedule åº“æ—¶çš„ç®€æ˜“å›é€€è°ƒåº¦ï¼šæŒ‰é—´éš”è½®è¯¢æ‰§è¡Œ
            interval = max(1, int(self.backup_interval_hours * 3600))
            next_time = time.time() + interval
            while self.is_running:
                now = time.time()
                if now >= next_time:
                    try:
                        self.create_backup()
                    except Exception as fb_exc:
                        logging.exception("å®šæ—¶å¤‡ä»½å¤±è´¥: %s", fb_exc)
                    next_time = now + interval
                time.sleep(60)

        # è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼ˆä¼˜å…ˆä½¿ç”¨ scheduleï¼›ç¼ºå¤±æ—¶é‡‡ç”¨å›é€€ï¼‰
        if sched is not None:
            try:
                sched.every(self.backup_interval_hours).hours.do(
                    self.create_backup
                )  # type: ignore[union-attr]
            except Exception as bind_exc:
                logging.warning("ç»‘å®š schedule å¤±è´¥ï¼Œå›é€€åˆ°ç®€æ˜“è°ƒåº¦: %s", bind_exc)
                self.backup_thread = threading.Thread(
                    target=run_scheduler_fallback,
                    daemon=True,
                )
            else:
                self.backup_thread = threading.Thread(
                    target=run_scheduler_with_schedule,
                    daemon=True,
                )
        else:
            logging.warning("æœªå®‰è£… schedule åº“ï¼Œä½¿ç”¨ç®€æ˜“å›é€€è°ƒåº¦")
            self.backup_thread = threading.Thread(
                target=run_scheduler_fallback,
                daemon=True,
            )

        self.backup_thread.start()

        logging.info(
            "ğŸš€ è‡ªåŠ¨å¤‡ä»½å·²å¯åŠ¨ï¼Œæ¯%så°æ—¶å¤‡ä»½ä¸€æ¬¡",
            self.backup_interval_hours,
        )

    def stop_auto_backup(self):
        """åœæ­¢è‡ªåŠ¨å¤‡ä»½"""
        self.is_running = False
        if self.backup_thread:
            self.backup_thread.join()
        logging.info("â¹ï¸ è‡ªåŠ¨å¤‡ä»½å·²åœæ­¢")

    def manual_backup(self):
        """æ‰‹åŠ¨åˆ›å»ºå¤‡ä»½"""
        logging.info("ğŸ“¦ å¼€å§‹æ‰‹åŠ¨å¤‡ä»½...")
        return self.create_backup()


# å…¨å±€å¤‡ä»½ç³»ç»Ÿå®ä¾‹
backup_system = AutoBackupSystem()


def start_backup_service():
    """å¯åŠ¨å¤‡ä»½æœåŠ¡"""
    backup_system.start_auto_backup()


def stop_backup_service():
    """åœæ­¢å¤‡ä»½æœåŠ¡"""
    backup_system.stop_auto_backup()


def create_manual_backup():
    """åˆ›å»ºæ‰‹åŠ¨å¤‡ä»½"""
    return backup_system.manual_backup()


def get_backup_info():
    """è·å–å¤‡ä»½ä¿¡æ¯"""
    return backup_system.get_backup_stats()


def restore_database(backup_filename):
    """æ¢å¤æ•°æ®åº“"""
    return backup_system.restore_from_backup(backup_filename)


if __name__ == "__main__":
    # æµ‹è¯•å¤‡ä»½ç³»ç»Ÿ
    print("ğŸ§ª æµ‹è¯•è‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿ...")

    # åˆ›å»ºæ‰‹åŠ¨å¤‡ä»½
    if create_manual_backup():
        print("âœ… æ‰‹åŠ¨å¤‡ä»½æµ‹è¯•æˆåŠŸ")
    else:
        print("âŒ æ‰‹åŠ¨å¤‡ä»½æµ‹è¯•å¤±è´¥")

    # è·å–å¤‡ä»½ä¿¡æ¯
    stats = get_backup_info()
    if stats:
        print(
            f"ğŸ“Š å¤‡ä»½ç»Ÿè®¡: {stats['count']} ä¸ªå¤‡ä»½æ–‡ä»¶ï¼Œ"
            f"æ€»å¤§å°: {stats['total_size_mb']} MB",
        )
        print("ğŸ“‹ æœ€æ–°å¤‡ä»½æ–‡ä»¶:")
        for entry in stats['files'][:3]:
            ts = entry['mtime'].strftime('%Y-%m-%d %H:%M:%S')
            print(f"  - {entry['name']} ({ts})")

    print("ğŸ¯ å¤‡ä»½ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
